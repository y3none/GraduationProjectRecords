## littlefs的设计

一个为微控制器设计的小型故障安全文件系统。

```
   | | |     .---._____
  .-----.   |          |
--|o    |---| littlefs |
--|     |---|          |
  '-----'   '----------'
   | | |
```

littlefs最初是作为一个实验项目诞生的，旨在探索在微控制器环境下如何设计文件系统。核心问题是：**如何在有限内存条件下构建一个既能抵御掉电风险又能平衡闪存磨损的文件系统？**

本文档将介绍littlefs的高层设计思路，其与其他文件系统的差异，以及关键设计决策的形成过程。若需了解磁盘上每一位的详细规范，请参阅[SPEC.md](./docs/技术文档/littlefs_SPEC_zh.md)。

## 问题背景

littlefs的目标平台通常是配备约32 KiB RAM和512 KiB ROM的32位微控制器。这些设备通常搭配约4 MiB容量的SPI NOR闪存芯片。这类设备资源有限，无法运行Linux或大多数现有文件系统，必须针对小型化设计。

闪存本身的特性也带来了挑战。与其他存储介质不同，写入闪存需要两个操作：**擦除（Erase）**和**编程（Program）**。编程（将位设置为0）成本较低且粒度较细，而擦除（将位设置为1）则需要昂贵且破坏性的操作，这也是闪存名称的由来。[Wikipedia][wikipedia-flash] 提供了更多关于闪存工作原理的详细信息。

更令人头疼的是，嵌入式系统可能随时掉电。通常，微控制器代码简单且响应式，没有正常关机的概念。这对持久化存储提出了严峻考验，意外掉电可能导致数据损坏甚至设备不可恢复。

因此，嵌入式文件系统需满足三大核心需求：

1. **掉电安全（Power-loss Resilience）**  
   在这些系统中，电源可能随时中断。如果掉电导致持久化数据结构损坏，设备可能无法恢复。嵌入式文件系统必须设计为在任何写入操作中都能从掉电中恢复。

2. **磨损均衡（Wear Leveling）**  
   写入闪存是破坏性的。如果文件系统反复写入同一块，最终该块会磨损失效。不考虑磨损的文件系统可能会快速耗尽用于存储频繁更新元数据的块，导致设备提前失效。

3. **有限资源（Bounded RAM/ROM）**  
   如果上述需求还不够，这些系统的内存资源也非常有限。这限制了许多现有文件系统设计，因为它们通常依赖大量RAM来临时存储文件系统元数据。

   - 对于ROM，这意味着设计需尽量简单，并尽可能复用代码路径。
   - 对于RAM，我们有更严格的要求：所有内存使用必须与文件系统规模无关。这意味着即使文件系统的大小或文件数量增加，内存使用量也不会增长。这带来了独特的挑战，即使是看似简单的操作（如遍历文件系统）也变得异常复杂

## 现有设计方案

那么，现有的文件系统有哪些呢？当然，有许多不同的文件系统，但它们通常彼此借鉴和共享特性。如果我们从掉电安全和磨损均衡的角度来看，可以将它们归纳为几种主要设计。

1. 首先是非掉电安全的块式文件系统，例如 [FAT] 和 [ext2]。这些是最早的文件系统设计，通常也是最简单的。在这种设计中，存储被划分为块，每个文件存储在一组块中。未经修改的情况下，这些文件系统不具备掉电安全性，因此更新文件只需简单地重写块。

   ```
               .--------.
               |  root  |
               |        |
               |        |
               '--------'
               .-'    '-.
              v          v
         .--------.  .--------.
         |   A    |  |   B    |
         |        |  |        |
         |        |  |        |
         '--------'  '--------'
         .-'         .-'    '-.
        v           v          v
   .--------.  .--------.  .--------.
   |   C    |  |   D    |  |   E    |
   |        |  |        |  |        |
   |        |  |        |  |        |
   '--------'  '--------'  '--------'
   ```

   由于它们的简单性，这些文件系统通常既快速又小巧。然而，缺乏掉电安全性是一个很大的问题，而且存储位置与数据的强绑定关系使得文件系统无法管理磨损。

2. 在完全不同的方向上，我们有日志文件系统，例如 [JFFS]、[YAFFS] 和 [SPIFFS]。在这种设计中，存储位置不与数据绑定，而是整个存储被用作一个循环日志，每次对文件系统的更改都会追加到日志中。写入时追加新更改，而读取时需要遍历日志以重建文件。一些日志文件系统会缓存文件以避免读取成本，但这会以增加 RAM 使用为代价。

   ```
                                                             v
   .--------.--------.--------.--------.--------.--------.--------.--------.
   |        C        | new B  | new A  |                 |   A    |   B    |
   |                 |        |        |->               |        |        |
   |                 |        |        |                 |        |        |
   '--------'--------'--------'--------'--------'--------'--------'--------'
   ```

   日志文件系统非常优雅。通过校验和，我们可以轻松检测掉电并通过忽略失败的追加操作回退到之前的状态。如果这还不够好，它们的循环性质意味着日志文件系统可以完美地分布磨损。

   主要缺点是性能。如果我们看垃圾回收的过程（即从日志末尾清理过时数据），我还没有见过一个纯日志文件系统不付出以下两种代价之一：

   1. _O(n²)_ 的时间复杂度
   2. _O(n)_ 的内存开销

   SPIFFS 是一个非常有趣的案例，它利用了 NOR 闪存的重复编程是原子且掩码的特性。这是一个非常巧妙的解决方案，但它限制了支持的存储类型。

3. 也许最常见的文件系统类型是日志式文件系统，它是块式文件系统与日志文件系统结合的产物。[ext4] 和 [NTFS] 是很好的例子。在这种设计中，我们采用一个普通的块式文件系统，并添加一个有限的日志，用于在每次更改发生之前记录更改。

   ```
                             journal
                            .--------.--------.
               .--------.   | C'| D'|     | E'|
               |  root  |-->|   |   |->   |   |
               |        |   |   |   |     |   |
               |        |   '--------'--------'
               '--------'
               .-'    '-.
              v          v
         .--------.  .--------.
         |   A    |  |   B    |
         |        |  |        |
         |        |  |        |
         '--------'  '--------'
         .-'         .-'    '-.
        v           v          v
   .--------.  .--------.  .--------.
   |   C    |  |   D    |  |   E    |
   |        |  |        |  |        |
   |        |  |        |  |        |
   '--------'  '--------'  '--------'
   ```

   这种文件系统结合了两者的优点。性能可以像块式文件系统一样快（尽管更新日志会带来一些小的开销），而日志的原子更新使得文件系统在掉电时能够恢复。

   不幸的是，日志式文件系统也有一些问题。它们相当复杂，因为实际上有两个文件系统在并行运行，这会增加代码大小。此外，由于存储位置与数据的强绑定关系，它们无法提供磨损保护。

4. 最后但同样重要的是写时复制（COW）文件系统，例如 [btrfs] 和 [ZFS]。这些文件系统与其他块式文件系统非常相似，但它们不是就地更新块，而是通过创建带有更改的副本并用新块替换对旧块的引用来执行所有更新。这会递归地将所有问题向上推，直到到达文件系统的根，而根通常存储在一个非常小的日志中。

   ```
               .--------.                  .--------.
               |  root  |       write      |new root|
               |        |        ==>       |        |
               |        |                  |        |
               '--------'                  '--------'
               .-'    '-.                    |    '-.
              |  .-------|------------------'        v
              v v        v                       .--------.
         .--------.  .--------.                  | new B  |
         |   A    |  |   B    |                  |        |
         |        |  |        |                  |        |
         |        |  |        |                  '--------'
         '--------'  '--------'                  .-'    |
         .-'         .-'    '-.    .------------|------'
        |           |          |  |             v
        v           v          v  v        .--------.
   .--------.  .--------.  .--------.      | new D  |
   |   C    |  |   D    |  |   E    |      |        |
   |        |  |        |  |        |      |        |
   |        |  |        |  |        |      '--------'
   '--------'  '--------'  '--------'
   ```

   COW 文件系统非常有趣。它们在性能上与块式文件系统非常相似，同时能够在不将数据更改直接存储在日志中的情况下实现原子更新。它们甚至解耦了数据的存储位置，这为磨损均衡提供了机会。

   不过，几乎是这样。更新的无界向上传播带来了一些问题。由于 COW 文件系统的更新不会停止，直到它们到达根，因此一次更新可能会级联成比原始数据所需更多的写入操作。除此之外，这种向上传播的更新会将这些写入集中在根块中，导致根块比其他部分更快磨损。

## littlefs

那么，littlefs 做了什么呢？

如果我们观察现有的文件系统，有两个有趣的设计模式脱颖而出，但它们各自都有一些问题。**日志**提供了独立的原子性，但运行时性能较差。而**写时复制（COW）数据结构**性能良好，却将原子性问题向上推。

我们能否绕过这些限制呢？

考虑日志。它要么有 _O(n²)_ 的时间复杂度，要么有 _O(n)_ 的内存开销。我们无法避免这些成本，**但如果我们对大小设置一个上限，至少可以防止理论成本成为实际问题**。这依赖于计算机科学中的一个“秘密技巧”：通过限制输入规模，你可以假装任何算法复杂度都是 _O(1)_。

对于 COW 数据结构，我们可以稍微调整一下定义。假设我们的 COW 结构不是在每次写入后都复制，而是在 _n_ 次写入后才复制。这不会改变大多数 COW 的特性（假设你可以原子地写入！），但它确实可以防止磨损的向上传播。这种**有限写时复制（CObW）**仍然会集中磨损，但在每一级我们将磨损传播除以 _n_。如果 _n_ 足够大（大于分支因子），磨损传播就不再是问题。

看出端倪了吗？单独的日志和 COW 都是不完美的解决方案，它们的弱点限制了它们的实用性。但如果我们将两者结合起来，它们可以相互弥补对方的局限性。

这就是 littlefs 的核心思想。在子块级别，littlefs 由小型的两块日志组成，这些日志可以在文件系统的任何地方提供元数据的原子更新。在超级块级别，littlefs 是一个 CObW 树，块可以根据需求被驱逐。

```
                    root
                   .--------.--------.
                   | A'| B'|         |
                   |   |   |->       |
                   |   |   |         |
                   '--------'--------'
                .----'   '--------------.
       A       v                 B       v
      .--------.--------.       .--------.--------.
      | C'| D'|         |       | E'|new|         |
      |   |   |->       |       |   | E'|->       |
      |   |   |         |       |   |   |         |
      '--------'--------'       '--------'--------'
      .-'   '--.                  |   '------------------.
     v          v              .-'                        v
.--------.  .--------.        v                       .--------.
|   C    |  |   D    |   .--------.       write       | new E  |
|        |  |        |   |   E    |        ==>        |        |
|        |  |        |   |        |                   |        |
'--------'  '--------'   |        |                   '--------'
                         '--------'                   .-'    |
                         .-'    '-.    .-------------|------'
                        v          v  v              v
                   .--------.  .--------.       .--------.
                   |   F    |  |   G    |       | new F  |
                   |        |  |        |       |        |
                   |        |  |        |       |        |
                   '--------'  '--------'       '--------'
```

仍然存在一些小问题。小型日志在存储方面可能代价较高，最坏情况下，一个小型日志的成本是原始数据的 4 倍。CObW 结构需要一个高效的块分配器，因为每 _n_ 次写入都会发生分配。此外，保持内存使用恒定仍然是一个挑战。

## 元数据对（Metadata Pairs）

元数据对是 littlefs 的核心。它们是由两个块组成的小型日志，可以在文件系统的任何地方提供原子更新。

为什么是两个块？日志通过将条目追加到存储在磁盘上的循环缓冲区中工作。但请记住，闪存的写入粒度有限。我们可以逐步将新数据编程到已擦除的块中，但擦除操作必须一次擦除整个块。这意味着为了让我们的循环缓冲区工作，我们需要不止一个块。

我们可以让日志大于两个块，但接下来的挑战是如何存储对这些日志的引用？由于块本身在写入时会被擦除，使用数据结构来跟踪这些块会变得复杂。这里的简单解决方案是为每个元数据对存储两个块地址。这样做的好处是，我们可以独立地更换元数据对中的块，并且不会降低其他操作的块粒度。

为了确定哪个元数据块是最新的，我们存储了一个修订号，并使用[序列算术][wikipedia-sna]进行比较（这在避免整数溢出问题时非常有用）。方便的是，这个修订号还让我们大致了解块上发生了多少次擦除。

```
元数据对指针: {block 0, block 1}
                           |        '--------------------.
                            '-.                           |
磁盘                           v                          v
.--------.--------.--------.--------.--------.--------.--------.--------.
|                 |        |metadata|                 |metadata|        |
|                 |        |block 0 |                 |block 1 |        |
|                 |        |        |                 |        |        |
'--------'--------'--------'--------'--------'--------'--------'--------'
                               '--.                  .----'
                                   v                v
             元数据对 .----------------.----------------.
                           |   revision 11  |   revision 12  |
             block 1 是    |----------------|----------------|
             最新的        |       A        |       A''      |
                           |----------------|----------------|
                           |    checksum    |    checksum    |
                           |----------------|----------------|
                           |       B        |       A'''     | <- 最新的 A
                           |----------------|----------------|
                           |       A''      |    checksum    |
                           |----------------|----------------|
                           |    checksum    |       |        |
                           |----------------|       v        |
                           '----------------'----------------'
```

那么我们如何原子地更新元数据对呢？原子性（一种掉电安全性）需要两个部分：冗余和错误检测。错误检测可以通过校验和提供，在 littlefs 中我们使用 32 位的 [CRC][wikipedia-crc]。而维护冗余则需要多个步骤。

1. 如果我们的块未满，并且程序的大小足够小，可以让我们追加更多条目，那么我们可以简单地将条目追加到日志中。因为我们不会覆盖原始条目（记住，重写闪存需要擦除），所以如果在追加过程中掉电，我们仍然保留原始条目。
   
   ```
                                    commit A
   .----------------.----------------.    .----------------.----------------.
   |   revision 1   |   revision 0   | => |   revision 1   |   revision 0   |
   |----------------|----------------|    |----------------|----------------|
   |       |        |                |    |       A        |                |
   |       v        |                |    |----------------|                |
   |                |                |    |    checksum    |                |
   |                |                |    |----------------|                |
   |                |                |    |       |        |                |
   |                |                |    |       v        |                |
   |                |                |    |                |                |
   |                |                |    |                |                |
   |                |                |    |                |                |
   |                |                |    |                |                |
   '----------------'----------------'    '----------------'----------------'
   ```
   
   需要注意的是，littlefs 不会为每个条目维护校验和。许多日志文件系统会这样做，但这限制了你在单个原子操作中可以更新的内容。相反，我们可以将多个条目分组到一个提交中，共享一个校验和。这让我们可以更新多个不相关的元数据，只要它们位于同一个元数据对中。
   
   ```
                                 commit B and A'
   .----------------.----------------.    .----------------.----------------.
   |   revision 1   |   revision 0   | => |   revision 1   |   revision 0   |
   |----------------|----------------|    |----------------|----------------|
   |       A        |                |    |       A        |                |
   |----------------|                |    |----------------|                |
   |    checksum    |                |    |    checksum    |                |
   |----------------|                |    |----------------|                |
   |       |        |                |    |       B        |                |
   |       v        |                |    |----------------|                |
   |                |                |    |       A'       |                |
   |                |                |    |----------------|                |
   |                |                |    |    checksum    |                |
   |                |                |    |----------------|                |
   '----------------'----------------'    '----------------'----------------'
   ```
   
2. 如果我们的块已经写满了条目，我们需要以某种方式删除过时的条目，以便为新条目腾出空间。这个过程称为垃圾回收，但由于 littlefs 有多个垃圾回收器，我们也称这种特定情况为压缩（compaction）。

   与其他文件系统相比，littlefs 的垃圾回收器相对简单。我们希望避免内存消耗，因此我们使用了一种类似暴力搜索的解决方案：对于每个条目，我们检查是否有更新的条目被写入。如果该条目是最新的，我们将其追加到新块中。这就是为什么有两个块变得很重要，因为如果掉电，我们仍然可以在原始块中找到所有内容。

   在压缩过程中，我们还会擦除元数据块并增加修订号。由于我们可以一次提交多个条目，因此我们可以将所有更改写入第二个块，而不用担心掉电。只有在提交的校验和被写入后，压缩的条目和修订号才会被提交并变为可读状态。

   ```
                           commit B', need to compact
   .----------------.----------------.    .----------------.----------------.
   |   revision 1   |   revision 0   | => |   revision 1   |   revision 2   |
   |----------------|----------------|    |----------------|----------------|
   |       A        |                |    |       A        |       A'       |
   |----------------|                |    |----------------|----------------|
   |    checksum    |                |    |    checksum    |       B'       |
   |----------------|                |    |----------------|----------------|
   |       B        |                |    |       B        |    checksum    |
   |----------------|                |    |----------------|----------------|
   |       A'       |                |    |       A'       |       |        |
   |----------------|                |    |----------------|       v        |
   |    checksum    |                |    |    checksum    |                |
   |----------------|                |    |----------------|                |
   '----------------'----------------'    '----------------'----------------'
   ```

3. 如果我们的块已经写满了条目，**并且我们找不到任何垃圾数据**，那该怎么办？此时，大多数日志文件系统会返回一个错误，表示没有更多可用空间。但由于我们使用的是小型日志，日志溢出并不真正是一个错误条件。

   相反，我们将原始的元数据对拆分为两个元数据对，每个元数据对包含一半的条目，并通过一个尾指针连接。与其增加日志的大小并处理与较大日志相关的可扩展性问题，我们形成一个小型有界日志的链表。这是一种权衡，因为这种方法确实会使用更多的存储空间，但好处是提高了可扩展性。

   尽管需要写入两个元数据对，我们仍然可以在拆分步骤中保持掉电安全性。具体做法是：首先准备新的元数据对，然后在提交到原始元数据对时插入尾指针。

   通过这种方式，我们可以在保持掉电安全性的同时，有效地扩展元数据对的容量。

```
                         commit C and D, need to split
   .----------------.----------------.    .----------------.----------------.
   |   revision 1   |   revision 2   | => |   revision 3   |   revision 2   |
   |----------------|----------------|    |----------------|----------------|
   |       A        |       A'       |    |       A'       |       A'       |
   |----------------|----------------|    |----------------|----------------|
   |    checksum    |       B'       |    |       B'       |       B'       |
   |----------------|----------------|    |----------------|----------------|
   |       B        |    checksum    |    |      tail    ---------------------.
   |----------------|----------------|    |----------------|----------------| |
   |       A'       |       |        |    |    checksum    |                | |
   |----------------|       v        |    |----------------|                | |
   |    checksum    |                |    |       |        |                | |
   |----------------|                |    |       v        |                | |
   '----------------'----------------'    '----------------'----------------' |
                                                   .----------------.---------'
                                                  v                v
                                          .----------------.----------------.
                                          |   revision 1   |   revision 0   |
                                          |----------------|----------------|
                                          |       C        |                |
                                          |----------------|                |
                                          |       D        |                |
                                          |----------------|                |
                                          |    checksum    |                |
                                          |----------------|                |
                                          |       |        |                |
                                          |       v        |                |
                                          |                |                |
                                          |                |                |
                                          '----------------'----------------'
```

在处理小型日志时，还存在另一个复杂问题。垃圾回收的平摊运行时间成本不仅取决于其一次性成本（littlefs 中为 _O(n²)_），还取决于垃圾回收发生的频率。

考虑两种极端情况：

1. **日志为空**，垃圾回收每 _n_ 次更新发生一次。
2. **日志已满**，垃圾回收**每次**更新都会发生。

显然，我们需要比等待元数据对填满更积极的策略。随着元数据对接近满的状态，压缩的频率会急剧增加。

从更一般的角度来看这个问题，假设日志中每个条目的大小为 n字节，d 是动态条目（在垃圾回收过程中过时的条目），s 是静态条目（在垃圾回收过程中需要复制的条目）。如果我们分析更新日志的平摊运行时间复杂性，可以得到以下公式：

这个公式表明，更新日志的成本不仅包括写入新条目的成本（n），还包括垃圾回收过程中复制静态条目的成本（n (s / d+1)）。随着日志接近满的状态，静态条目的比例增加，垃圾回收的成本也会显著增加。

![][metadata-formula1]

如果我们设 r 为静态空间与日志总大小的比例（以字节为单位），我们可以找到静态条目和动态条目的另一种表示形式：

![][metadata-formula2]

![][metadata-formula3]

将这些 d 和 s 的表达式代入，我们可以得到一个关于日志满度与更新成本的简洁公式：

![][metadata-formula4]

假设日志中每个条目的大小为 100 字节，日志总大小为 4 KiB，我们可以通过条目大小绘制图表，找到更新成本的乘数因子。

![Metadata pair update cost graph][metadata-cost-graph]

因此，当日志使用率达到 50% 时，每次更新的平均成本约为原始成本的 2 倍；当日志使用率达到 75% 时，每次更新的平均成本已经增加到原始成本的 4 倍。

为了避免这种指数级增长，我们不会等到元数据对完全满时才进行拆分，而是在日志使用率超过 50% 时就进行拆分。我们采用惰性策略，只有在需要压缩时才检查是否超过了 50% 的限制。这可以将垃圾回收的开销限制在 2 倍的运行时间成本内，从而使平摊运行时间复杂性保持在 *O(1)*。

---

如果我们从高层次来看元数据对和元数据对的链表，它们的运行时间成本相当不错。假设有 *n* 个元数据对，每个元数据对包含 *m* 个元数据条目，那么查找特定条目的最坏情况运行时间复杂性为 *O(nm)*。对于更新特定条目，最坏情况的复杂性为 *O(nm²)*，而平摊复杂性仅为 *O(nm)*。

然而，在 50% 容量时进行拆分确实意味着在最佳情况下，我们的元数据对只会填满一半。如果我们考虑到元数据对中第二个块的开销，每个元数据条目的有效存储成本是原始大小的 4 倍。我想如果用户发现他们只能使用原始存储的四分之一，他们不会感到高兴。元数据对提供了一种执行原子更新的机制，但我们需要另一种机制来存储大部分数据。

## CTZ 跳跃列表（CTZ Skip-lists）

元数据对提供了高效的原子更新，但不幸的是，它们的存储成本很高。不过，我们可以通过仅使用元数据对存储对更密集的写时复制（COW）数据结构的引用来绕过这一存储成本。

[写时复制数据结构][wikipedia-cow]，也称为纯函数式数据结构，是一类底层元素不可变的数据结构。对数据进行更改需要创建包含更新数据副本的新元素，并用对新元素的引用替换旧引用。通常，COW 数据结构的性能取决于在替换部分数据后可以重用多少旧元素。

littlefs 对其 COW 结构有几个要求。它们需要高效地读取和写入，但最令人头疼的是，它们需要在恒定的 RAM 下可遍历。这显然排除了 [B 树][wikipedia-B-tree]（无法在恒定 RAM 下遍历）和 [B+ 树][wikipedia-B+-tree]（无法通过 COW 操作更新）。

---

那么，我们能做些什么呢？首先，让我们考虑将文件存储在简单的 COW 链表中。追加一个块（这是写入文件的基础操作）意味着我们必须更新最后一个块以指向新块。这需要 COW 操作，也就是说，我们需要更新倒数第二个块，然后是倒数第三个块，依此类推，直到我们复制了整个文件。

```
一个链表
.--------.  .--------.  .--------.  .--------.  .--------.  .--------.
| data 0 |->| data 1 |->| data 2 |->| data 4 |->| data 5 |->| data 6 |
|        |  |        |  |        |  |        |  |        |  |        |
|        |  |        |  |        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'  '--------'
```

为了避免在追加时进行完整的复制，我们可以将数据反向存储。追加块只需要添加新块，而不需要更新其他块。如果我们更新中间的某个块，仍然需要复制其后的块，但可以重用其前的所有块。由于大多数文件写入是线性的，这种设计赌的是追加是最常见的数据更新类型。

```
一个反向链表
.--------.  .--------.  .--------.  .--------.  .--------.  .--------.
| data 0 |<-| data 1 |<-| data 2 |<-| data 4 |<-| data 5 |<-| data 6 |
|        |  |        |  |        |  |        |  |        |  |        |
|        |  |        |  |        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'  '--------'
```

然而，反向链表确实有一个非常明显的问题。按顺序遍历文件的运行时间成本为 _O(n²)_。仅仅为了读取一个文件就需要二次方的时间复杂度！这太糟糕了。

幸运的是，我们可以做得更好。littlefs 没有使用单链表，而是使用了一种多层链表，通常称为[跳跃列表][wikipedia-skip-list]。然而，与最常见的跳跃列表不同，littlefs 的跳跃列表是严格确定性的，基于**末尾零计数（CTZ）指令**的一些有趣特性构建。

CTZ 跳跃列表遵循的规则是：对于每个第 _n_ 个块（其中 _n_ 能被 2&zwj;_&#739;_ 整除），该块包含一个指向第 _n_-2&zwj;_&#739;_ 块的指针。这意味着每个块包含 1 到 log&#8322;_n_ 个指针，这些指针跳转到跳跃列表中不同的前驱元素。

这种结构的名称来源于对 [CTZ 指令][wikipedia-ctz] 的频繁使用，该指令可以高效地计算 2 的幂次因子。对于给定的块 _n_，该块包含 ctz(_n_)+1 个指针。

```
一个反向 CTZ 跳跃列表
.--------.  .--------.  .--------.  .--------.  .--------.  .--------.
| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |<-| data 4 |<-| data 5 |
|        |<-|        |--|        |<-|        |--|        |  |        |
|        |<-|        |--|        |--|        |--|        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'  '--------'
```

这些额外的指针使我们能够比单链表更高效地在磁盘上导航数据结构。

考虑从数据块 5 到数据块 1 的路径。你可以看到数据块 3 被完全跳过了：

```
.--------.  .--------.  .--------.  .--------.  .--------.  .--------.
| data 0 |  | data 1 |<-| data 2 |  | data 3 |  | data 4 |<-| data 5 |
|        |  |        |  |        |<-|        |--|        |  |        |
|        |  |        |  |        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'  '--------'
```

到数据块 0 的路径更快，只需要两次跳跃：

```
.--------.  .--------.  .--------.  .--------.  .--------.  .--------.
| data 0 |  | data 1 |  | data 2 |  | data 3 |  | data 4 |<-| data 5 |
|        |  |        |  |        |  |        |  |        |  |        |
|        |<-|        |--|        |--|        |--|        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'  '--------'
```

我们可以通过从包含最多指针的块到任何块的路径来分析运行时间复杂性。路径上的每一步都将块的搜索空间减半，因此运行时间为 _O(log n)_。要到达包含最多指针的块，我们可以反向执行相同的步骤，这使得运行时间为 _O(2 log n)_ = _O(log n)_。有趣的是，如果我们贪心地选择覆盖最大距离而不超过目标的指针，这种最优路径会自然出现。

因此，我们现在有了一个 [COW] 数据结构，它的追加操作成本为 _O(1)_，读取操作的最坏情况运行时间为 _O(n log n)_。考虑到这个运行时间还会被每个块中存储的数据量所分摊，这个成本是相当合理的。

---

1. 这是一个新的数据结构，因此我们仍然有几个问题需要解决。存储开销是多少？指针的数量是否会超过块的大小？我们如何在元数据对中存储 CTZ 跳跃列表？

   为了计算存储开销，我们可以将数据结构视为多个链表。每个链表跳过的块数是前一个链表的两倍，或者从另一个角度来看，每个链表使用的存储空间是前一个链表的一半。随着链表数量趋近于无穷大，存储开销形成一个几何级数。通过求解这个级数，我们发现平均每个块的存储开销仅为 2 个指针。

   ![][ctz-formula1]

   由于文件大小受限于我们用于存储大小的字宽，我们还可以计算出一个块中可能需要的最大指针数量。如果我们将指针的开销设置为等于块大小，可以得到以下方程。注意，较小的块大小 B 和较大的字宽 (w) 都会导致更多的存储开销。

   ![][ctz-formula2]

   通过求解这个方程，我们可以得到一些常见字宽下的最小块大小：

   1. 32 位 CTZ 跳跃列表 => 最小块大小为 104 字节
   2. 64 位 CTZ 跳跃列表 => 最小块大小为 448 字节

littlefs 使用 32 位字宽，因此只有当块大小小于 104 字节时，块中的指针才可能溢出。这是一个很容易满足的要求，因为在实际应用中，大多数块大小从 512 字节开始。只要我们的块大小大于 104 字节，就可以避免处理指针溢出所需的额外逻辑。

最后一个问题是如何存储 CTZ 跳跃列表？我们需要一个指向头块的指针、跳跃列表的大小、头块的索引以及我们在头块中的偏移量。但值得注意的是，每个大小都映射到一个唯一的索引 + 偏移量对。因此，理论上我们只需要存储一个指针和大小。

然而，从大小计算索引 + 偏移量对有点复杂。我们可以从一个求和公式开始，遍历所有块直到达到给定的大小。设 B为块大小（以字节为单位），w 为字宽（以位为单位），n 为跳跃列表中块的索引，N为文件大小（以字节为单位）：

![][ctz-formula3]

这个公式虽然有效，但需要 _O(n)_ 的时间来计算，这使得读取文件的整体运行时间增加到 _O(n² log n)_。幸运的是，这个求和操作不需要访问磁盘，因此实际影响很小。

然而，尽管涉及位运算，我们实际上可以将这个方程简化为 _O(1)_ 的形式。在浏览了令人惊叹的资源 [整数序列在线百科全书 (OEIS)][oeis] 后，我找到了 [A001511]，它与 CTZ 指令的迭代相匹配，以及 [A005187]，它与部分求和相匹配。令我惊讶的是，这两者都源于简单的方程，这让我们发现了一个将两个看似无关的位运算指令联系起来的非直观特性：

![][ctz-formula4]

其中：
1. ctz(x) = x 中末尾零的数量。
2. popcount(x) = x 中 1 的数量。

初步测试表明，这个令人惊讶的特性似乎成立。当 n 趋近于无穷大时，我们得到的平均开销为 2 个指针，这与我们之前的假设一致。在迭代过程中，popcount 函数似乎处理了与平均值的偏差。当然，为了确保这一点，我编写了一个快速脚本，验证了这个特性对所有 32 位整数都成立。

现在我们可以将其代入原始方程，找到一个更高效的文件大小公式：

![][ctz-formula5]

不幸的是，popcount 函数不是单射的，因此我们无法直接从该方程求解索引 n。但我们可以求解一个大于 n 的 n 索引，其误差由 popcount 函数的范围限定。我们可以反复将 ![n'] 代入原始方程，直到误差小于我们的整数分辨率。事实证明，我们只需要进行一次替换，就可以得到索引的公式：

![][ctz-formula6]

现在我们已经得到了索引 n，我们可以将其代入上述方程来找到偏移量。我们遇到了一些整数溢出的问题，但可以通过重新排列方程来避免：

![][ctz-formula7]

我们的解决方案涉及相当多的数学运算，但计算机非常擅长数学。现在我们可以通过大小在 _O(1)_ 时间内找到块索引和偏移量，从而仅使用一个指针和大小来存储 CTZ 跳跃列表。

CTZ 跳跃列表为我们提供了一种 COW 数据结构，它可以在 *O(n)* 时间内轻松遍历，可以在 *O(1)* 时间内追加，并且可以在 *O(n log n)* 时间内读取。所有这些操作都在有限的内存中运行，并且每个块只需要两个字的存储开销。结合元数据对，CTZ 跳跃列表提供了掉电安全性和紧凑的数据存储。

```
                                    .--------.
                                   .|metadata|
                                   ||        |
                                   ||        |
                                   |'--------'
                                   '----|---'
                                        v
.--------.  .--------.  .--------.  .--------.
| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |
|        |<-|        |--|        |  |        |
|        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'

write data to disk, create copies
=>
                                    .--------.
                                   .|metadata|
                                   ||        |
                                   ||        |
                                   |'--------'
                                   '----|---'
                                        v
.--------.  .--------.  .--------.  .--------.
| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |
|        |<-|        |--|        |  |        |
|        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'
     ^ ^           ^
     | |           |    .--------.  .--------.  .--------.  .--------.
     | |           '----| new    |<-| new    |<-| new    |<-| new    |
     | '----------------| data 2 |<-| data 3 |--| data 4 |  | data 5 |
     '------------------|        |--|        |--|        |  |        |
                        '--------'  '--------'  '--------'  '--------'

commit to metadata pair
=>
                                                            .--------.
                                                           .|new     |
                                                           ||metadata|
                                                           ||        |
                                                           |'--------'
                                                           '----|---'
                                                                |
.--------.  .--------.  .--------.  .--------.                  |
| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |                  |
|        |<-|        |--|        |  |        |                  |
|        |  |        |  |        |  |        |                  |
'--------'  '--------'  '--------'  '--------'                  |
     ^ ^           ^                                            v
     | |           |    .--------.  .--------.  .--------.  .--------.
     | |           '----| new    |<-| new    |<-| new    |<-| new    |
     | '----------------| data 2 |<-| data 3 |--| data 4 |  | data 5 |
     '------------------|        |--|        |--|        |  |        |
                        '--------'  '--------'  '--------'  '--------'
```

## 块分配器（Block Allocator）

现在我们已经有了一个支持原子操作和磨损均衡的文件系统框架。小型的两块元数据对提供了原子更新，而 CTZ 跳跃列表则在 COW 块中提供了紧凑的数据存储。

但现在我们需要面对一个显而易见的问题：所有这些块是从哪里来的？

决定下一个使用哪个块是块分配器的职责。在文件系统设计中，块分配通常是一个次要问题，但在 COW 文件系统中，它的角色变得非常重要，因为几乎每次写入文件系统都需要进行块分配。

通常，块分配涉及某种存储在文件系统上的空闲列表或位图，这些结构会随着空闲块的更新而更新。然而，在掉电安全性的要求下，保持这些结构的一致性变得非常困难。更糟糕的是，更新这些结构时的任何错误都可能导致块丢失，且无法恢复。

littlefs 采取了一种谨慎的方法。它不依赖于磁盘上的空闲列表，而是依赖于磁盘上的文件系统是空闲块的镜像这一事实。块分配器的操作方式类似于脚本语言中的垃圾回收器，按需扫描未使用的块。

复制

```
          .----.
          |root|
          |    |
          '----'
   v-------'  '-------v
.----.    .    .    .----.
| A  |    .    .    | B  |
|    |    .    .    |    |
'----'    .    .    '----'
.    .    .    .  v--'  '------------v---------v
.    .    .    .----.    .         .----.    .----.
.    .    .    | C  |    .         | D  |    | E  |
.    .    .    |    |    .         |    |    |    |
.    .    .    '----'    .         '----'    '----'
.    .    .    .    .    .         .    .    .    .
.----.----.----.----.----.----.----.----.----.----.----.----.
| A  |    |root| C  | B  |         | D  |    | E  |         |
|    |    |    |    |    |         |    |    |    |         |
'----'----'----'----'----'----'----'----'----'----'----'----'
        ^                   ^    ^                   ^    ^
         '-------------------'----'-------------------'----'-- 空闲块
```

虽然这种方法听起来可能有些复杂，但不维护空闲列表的决定极大地简化了 littlefs 的整体设计。与编程语言不同，我们只需要遍历少数几种数据结构。而块释放（几乎与块分配一样频繁）则只是一个空操作。这种“直接丢弃”的策略大大降低了管理磁盘数据结构的复杂性，尤其是在处理高风险错误条件时

---

我们的块分配器需要高效地找到空闲块。你可以遍历存储中的每个块，并将其与文件系统树进行对比；然而，这种运行时间会非常糟糕。我们需要以某种方式在每次遍历中收集多个块。

观察现有的设计，一些使用类似“直接丢弃”策略的较大文件系统会在 [RAM] 中存储整个存储的位图。这种方法效果很好，因为位图非常紧凑。我们不能在这里使用相同的策略，因为它违反了我们的恒定内存要求，但我们或许可以修改这个想法，使其成为一个可行的解决方案。

复制

```
.----.----.----.----.----.----.----.----.----.----.----.----.
| A  |    |root| C  | B  |         | D  |    | E  |         |
|    |    |    |    |    |         |    |    |    |         |
'----'----'----'----'----'----'----'----'----'----'----'----'
  1    0    1    1    1    0    0    1    0    1    0    0
 \---------------------------+----------------------------/
                             v
               位图: 0xb94 (0b101110010100)
```

littlefs 中的块分配器是磁盘大小位图和暴力遍历之间的折衷方案。我们不是使用与存储大小相同的位图，而是跟踪一个小的、固定大小的位图，称为**前瞻缓冲区（lookahead buffer）**。在块分配期间，我们从前瞻缓冲区中获取块。如果前瞻缓冲区为空，我们扫描文件系统以查找更多空闲块，填充我们的前瞻缓冲区。在每次扫描中，我们使用一个递增的偏移量，随着块的分配循环遍历存储。

以下是在一个相对繁忙的文件系统上分配 4 个块的示例，假设使用 32 位的前瞻缓冲区，总共有 128 个块（如果块大小为 4 KiB，则存储为 512 KiB）：

```
boot...         lookahead:
                fs blocks: fffff9fffffffffeffffffffffff0000
scanning...     lookahead: fffff9ff
                fs blocks: fffff9fffffffffeffffffffffff0000
alloc = 21      lookahead: fffffdff
                fs blocks: fffffdfffffffffeffffffffffff0000
alloc = 22      lookahead: ffffffff
                fs blocks: fffffffffffffffeffffffffffff0000
scanning...     lookahead:         fffffffe
                fs blocks: fffffffffffffffeffffffffffff0000
alloc = 63      lookahead:         ffffffff
                fs blocks: ffffffffffffffffffffffffffff0000
scanning...     lookahead:         ffffffff
                fs blocks: ffffffffffffffffffffffffffff0000
scanning...     lookahead:                 ffffffff
                fs blocks: ffffffffffffffffffffffffffff0000
scanning...     lookahead:                         ffff0000
                fs blocks: ffffffffffffffffffffffffffff0000
alloc = 112     lookahead:                         ffff8000
                fs blocks: ffffffffffffffffffffffffffff8000
```

这种前瞻方法的运行时间复杂性为 *O(n²)*，以完全扫描存储；然而，位图非常紧凑，实际上通常只需要一两次扫描就能找到空闲块。此外，可以通过调整块大小或前瞻缓冲区的大小来优化分配器的性能，以写入粒度或内存换取分配器性能。

## 磨损均衡（Wear Leveling）

块分配器还有一个次要角色：磨损均衡。

磨损均衡是将写操作均匀分布到存储中的所有块上，以防止文件系统因单个块的过度磨损而过早失效。

littlefs 有两种保护机制来应对磨损：

1. **坏块检测与恢复**
2. **动态块的均匀磨损分布**

---

坏块恢复实际上与块分配器本身无关。相反，它依赖于文件系统在坏块发生时检测并驱逐坏块的能力。

在 littlefs 中，检测坏块在写入时相对简单。所有写入操作都必须基于 RAM 中的某些数据，因此在我们写入块后，可以立即读取数据并验证其是否正确写入。如果发现磁盘上的数据与 RAM 中的副本不匹配，则发生了写入错误，很可能是一个坏块。

一旦检测到坏块，我们需要从中恢复。对于写入错误，我们已经在 RAM 中保存了损坏数据的副本，因此我们只需要驱逐坏块，分配一个新的（希望是好的）块，并重试之前失败的写入操作。

驱逐坏块并用新块替换的实际操作由文件系统的**有限写时复制（CObW）**数据结构处理。CObW 数据结构的一个特性是，在 COW 操作期间可以替换任何块。有限写入部分通常由计数器触发，但没有什么能阻止我们在发现坏块时立即触发 COW 操作。

```
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.                        .----.
| A  |                        | B  |
|    |                        |    |
'----'                        '----'
.    .                      v---'  .
.    .                   .----.    .
.    .                   | C  |    .
.    .                   |    |    .
.    .                   '----'    .
.    .                   .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root|              | C  | B  |              |
|    |    |              |    |    |              |
'----'----'----'----'----'----'----'----'----'----'

update C
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.                        .----.
| A  |                        | B  |
|    |                        |    |
'----'                        '----'
.    .                      v---'  .
.    .                   .----.    .
.    .                   |bad |    .
.    .                   |blck|    .
.    .                   '----'    .
.    .                   .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root|              |bad | B  |              |
|    |    |              |blck|    |              |
'----'----'----'----'----'----'----'----'----'----'

oh no! bad block! relocate C
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.                        .----.
| A  |                        | B  |
|    |                        |    |
'----'                        '----'
.    .                      v---'  .
.    .                   .----.    .
.    .                   |bad |    .
.    .                   |blck|    .
.    .                   '----'    .
.    .                   .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root|              |bad | B  |bad |         |
|    |    |              |blck|    |blck|         |
'----'----'----'----'----'----'----'----'----'----'
                            --------->
oh no! bad block! relocate C
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.                        .----.
| A  |                        | B  |
|    |                        |    |
'----'                        '----'
.    .                      v---'  .
.    .                   .----.    .    .----.
.    .                   |bad |    .    | C' |
.    .                   |blck|    .    |    |
.    .                   '----'    .    '----'
.    .                   .    .    .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root|              |bad | B  |bad | C' |    |
|    |    |              |blck|    |blck|    |    |
'----'----'----'----'----'----'----'----'----'----'
                            -------------->
successfully relocated C, update B
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.                        .----.
| A  |                        |bad |
|    |                        |blck|
'----'                        '----'
.    .                      v---'  .
.    .                   .----.    .    .----.
.    .                   |bad |    .    | C' |
.    .                   |blck|    .    |    |
.    .                   '----'    .    '----'
.    .                   .    .    .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root|              |bad |bad |bad | C' |    |
|    |    |              |blck|blck|blck|    |    |
'----'----'----'----'----'----'----'----'----'----'

oh no! bad block! relocate B
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.                        .----.         .----.
| A  |                        |bad |         |bad |
|    |                        |blck|         |blck|
'----'                        '----'         '----'
.    .                      v---'  .         .    .
.    .                   .----.    .    .----.    .
.    .                   |bad |    .    | C' |    .
.    .                   |blck|    .    |    |    .
.    .                   '----'    .    '----'    .
.    .                   .    .    .    .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root|              |bad |bad |bad | C' |bad |
|    |    |              |blck|blck|blck|    |blck|
'----'----'----'----'----'----'----'----'----'----'
                                 -------------->
oh no! bad block! relocate B
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '----------------------v
.----.    .----.              .----.
| A  |    | B' |              |bad |
|    |    |    |              |blck|
'----'    '----'              '----'
.    .    .  | .            .---'  .
.    .    .  '--------------v-------------v
.    .    .    .         .----.    .    .----.
.    .    .    .         |bad |    .    | C' |
.    .    .    .         |blck|    .    |    |
.    .    .    .         '----'    .    '----'
.    .    .    .         .    .    .    .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root| B' |         |bad |bad |bad | C' |bad |
|    |    |    |         |blck|blck|blck|    |blck|
'----'----'----'----'----'----'----'----'----'----'
------------>                    ------------------
successfully relocated B, update root
=>
     .----.
     |root|
     |    |
     '----'
   v--'  '--v
.----.    .----.
| A  |    | B' |
|    |    |    |
'----'    '----'
.    .    .   '---------------------------v
.    .    .    .                        .----.
.    .    .    .                        | C' |
.    .    .    .                        |    |
.    .    .    .                        '----'
.    .    .    .                        .    .
.----.----.----.----.----.----.----.----.----.----.
| A  |root| B' |         |bad |bad |bad | C' |bad |
|    |    |    |         |blck|blck|blck|    |blck|
'----'----'----'----'----'----'----'----'----'----'
```

我们可能会发现新块也是坏的，但希望经过多次重复这个过程后，最终能找到一个写入成功的新块。如果没有，那意味着我们存储中的所有块都坏了，设备的使用寿命已经结束。此时，littlefs 将返回“空间不足”错误。这在技术上是正确的，因为没有更多的好块了，但作为一个额外的好处，它也符合动态大小数据用户预期的错误条件。

---

另一方面，读取错误则要复杂得多。我们没有在 RAM 中保留数据的副本，因此需要一种方法在数据损坏后重建原始数据。一种实现这一目标的机制是[纠错码（ECC）][wikipedia-ecc]。

ECC 是校验和概念的扩展。像 CRC 这样的校验和可以检测数据中是否发生了错误，而 ECC 不仅可以检测错误，还可以纠正一定数量的错误。然而，ECC 能够检测的错误数量是有限的：[汉明界][wikipedia-hamming-bound]。随着错误数量接近汉明界，我们可能仍然能够检测到错误，但无法再修复数据。如果达到这一点，块将无法恢复。

littlefs 本身**不**提供 ECC。ECC 的块性质和相对较大的存储占用与文件系统的动态大小数据不太兼容，而且在没有 RAM 的情况下纠正错误非常复杂，ECC 更适合块设备的几何结构。事实上，许多 NOR 闪存芯片都有用于 ECC 的额外存储空间，而许多 NAND 芯片甚至可以在芯片本身上计算 ECC。

在 littlefs 中，ECC 完全是可选的。读取错误可以通过磨损均衡主动预防。但需要注意的是，ECC 可以在块设备级别使用，以适度延长设备的寿命。littlefs 会尊重块设备报告的任何错误，允许块设备提供更激进的错误检测。

---

为了避免读取错误，我们需要采取主动措施，而不是像处理写入错误时那样被动应对。

一种方法是在块中的错误数量超过某个阈值但仍可恢复时进行检测。使用 ECC，我们可以在写入时做到这一点，并将错误视为写入错误，在致命的读取错误发生之前驱逐该块。

另一种更通用的策略是主动将磨损均匀分布到存储中的所有块上，希望没有单个块在存储的其他部分接近使用寿命结束之前失效。这被称为**磨损均衡**。

通常，磨损均衡算法分为两类：

1. [动态磨损均衡][wikipedia-dynamic-wear-leveling]：我们将磨损分布在“动态”块上。这可以通过仅考虑未使用的块来实现。
2. [静态磨损均衡][wikipedia-static-wear-leveling]：我们将磨损分布在“动态”和“静态”块上。为了实现这一点，我们需要考虑所有块，包括已经包含数据的块。

为了在代码大小和复杂性之间取得平衡，littlefs（目前）仅提供动态磨损均衡。这是一种尽力而为的解决方案。磨损并不是完美分布的，但它会在空闲块之间分布，并大大延长设备的使用寿命。

在此基础上，littlefs 使用了一种**统计磨损均衡算法**。这意味着我们不会主动跟踪磨损，而是依赖于存储中磨损的均匀分布来近似实现动态磨损均衡算法。尽管名字很长，但这实际上是动态磨损均衡的一种简化。

磨损的均匀分布由块分配器负责，它通过两部分实现均匀分布。简单的部分是设备通电时，我们线性分配块，循环遍历设备。较难的部分是设备掉电时如何处理。我们不能简单地从存储的开头重新启动分配器，因为这会导致磨损偏向。相反，我们每次挂载文件系统时都会从一个随机偏移量开始分配器。只要这个随机偏移量是均匀的，组合的分配模式也是均匀分布。

![Cumulative wear distribution graph][wear-distribution-graph]

最初，这种磨损均衡方法看起来像是依赖于一个独立于电源的随机数生成器，它必须在每次启动时返回不同的随机数。然而，文件系统处于一个相对独特的情况，因为它位于大量跨电源丢失的熵之上。

我们实际上可以使用磁盘上的数据直接驱动我们的随机数生成器。在实践中，这是通过对每个元数据对的校验和进行异或操作来实现的，这些校验和在获取和挂载文件系统时已经计算过。

```
            .--------. \                         probably random
           .|metadata| |                                ^
           ||        | +-> crc ----------------------> xor
           ||        | |                                ^
           |'--------' /                                |
           '---|--|-'                                   |
            .-'    '-------------------------.          |
           |                                  |         |
           |        .--------------> xor ------------> xor
           |        |                 ^       |         ^
           v       crc               crc      v        crc
      .--------. \  ^   .--------. \  ^   .--------. \  ^
     .|metadata|-|--|-->|metadata| |  |  .|metadata| |  |
     ||        | +--'  ||        | +--'  ||        | +--'
     ||        | |     ||        | |     ||        | |
     |'--------' /     |'--------' /     |'--------' /
     '---|--|-'        '----|---'        '---|--|-'
      .-'    '-.            |             .-'    '-.
     v          v           v            v          v
.--------.  .--------.  .--------.  .--------.  .--------.
|  data  |  |  data  |  |  data  |  |  data  |  |  data  |
|        |  |        |  |        |  |        |  |        |
|        |  |        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'
```

需要注意的是，这个随机数生成器并不完美。它只在文件系统被修改时返回唯一的随机数。这正是我们分配器中分布磨损所需要的，但意味着这个随机数生成器不适用于一般用途。

---

综上所述，坏块检测和动态磨损均衡提供了一种尽力而为的解决方案，用于避免文件系统因磨损而过早失效。重要的是，littlefs 的磨损均衡算法提供了一个关键特性：**只需增加存储的大小，就可以延长设备的使用寿命**。如果需要更激进的磨损均衡，你可以将 littlefs 与[闪存转换层（FTL）][wikipedia-ftl]结合使用，以获得一个具有静态磨损均衡的小型掉电安全文件系统。

## 文件（Files）

现在我们已经介绍了基础构建模块，接下来可以开始从整体上看待我们的文件系统了。

第一步：我们如何实际存储文件？

我们已经确定 CTZ 跳跃列表在紧凑存储数据方面表现良好，因此按照其他文件系统的惯例，我们可以为每个文件分配一个存储在元数据对中的跳跃列表，作为文件的 inode。

```
                                    .--------.
                                   .|metadata|
                                   ||        |
                                   ||        |
                                   |'--------'
                                   '----|---'
                                        v
.--------.  .--------.  .--------.  .--------.
| data 0 |<-| data 1 |<-| data 2 |<-| data 3 |
|        |<-|        |--|        |  |        |
|        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'
```

然而，当文件较小时，这种方法效果不佳，而这在嵌入式系统中很常见。与 PC 相比，嵌入式系统中的**所有**数据都很小。

考虑一个 4 字节的小文件。使用一个两块的元数据对和一个块用于 CTZ 跳跃列表，我们会发现自己使用了整整 3 个块。在大多数块大小为 4 KiB 的 NOR 闪存上，这意味着 12 KiB 的开销。这是一个荒谬的 3072 倍增长。

```
file stored as inode, 4 bytes costs ~12 KiB

 .----------------.                  \
.|    revision    |                  |
||----------------|    \             |
||    skiplist   ---.  +- metadata   |
||----------------| |  /  4x8 bytes  |
||    checksum    | |     32 bytes   |
||----------------| |                |
||       |        | |                +- metadata pair
||       v        | |                |  2x4 KiB
||                | |                |  8 KiB
||                | |                |
||                | |                |
||                | |                |
|'----------------' |                |
'----------------'  |                /
          .--------'
         v
 .----------------.    \             \
 |      data      |    +- data       |
 |----------------|    /  4 bytes    |
 |                |                  |
 |                |                  |
 |                |                  |
 |                |                  +- data block
 |                |                  |  4 KiB
 |                |                  |
 |                |                  |
 |                |                  |
 |                |                  |
 |                |                  |
 '----------------'                  /
```

我们可以进行一些改进。首先，我们可以将多个文件存储在单个元数据对中，而不是为每个文件分配一个元数据对。一种方法是将目录直接与元数据对（或元数据对的链表）关联。这使得多个文件可以共享目录的元数据对进行日志记录，并减少集体存储开销。

元数据对和目录的严格绑定还使用户能够根据目录的组织方式直接控制存储利用率。

```
multiple files stored in metadata pair, 4 bytes costs ~4 KiB

       .----------------.
      .|    revision    |
      ||----------------|
      ||    A name      |
      ||   A skiplist  -----.
      ||----------------|   |  \
      ||    B name      |   |  +- metadata
      ||   B skiplist  ---. |  |  4x8 bytes
      ||----------------| | |  /  32 bytes
      ||    checksum    | | |
      ||----------------| | |
      ||       |        | | |
      ||       v        | | |
      |'----------------' | |
      '----------------'  | |
         .----------------' |
        v                   v
.----------------.  .----------------.  \           \
|     A data     |  |     B data     |  +- data     |
|                |  |----------------|  /  4 bytes  |
|                |  |                |              |
|                |  |                |              |
|                |  |                |              |
|                |  |                |              + data block
|                |  |                |              | 4 KiB
|                |  |                |              |
|----------------|  |                |              |
|                |  |                |              |
|                |  |                |              |
|                |  |                |              |
'----------------'  '----------------'              /
```

第二个改进是注意到对于非常小的文件，我们尝试使用 CTZ 跳跃列表进行紧凑存储的效果适得其反。元数据对的存储开销约为 4 倍，因此如果文件大小小于块大小的 1/4，实际上将文件存储在元数据对外部并没有好处。

在这种情况下，我们可以将文件直接存储在目录的元数据对中。我们称这种文件为**内联文件**，它允许目录高效地存储许多小文件。我们之前的 4 字节文件现在在磁盘上仅占用理论上的 16 字节。

```
inline files stored in metadata pair, 4 bytes costs ~16 bytes

 .----------------.
.|    revision    |
||----------------|
||    A name      |
||   A skiplist  ---.
||----------------| |  \
||    B name      | |  +- data
||    B data      | |  |  4x4 bytes
||----------------| |  /  16 bytes
||    checksum    | |
||----------------| |
||       |        | |
||       v        | |
|'----------------' |
'----------------'  |
          .---------'
         v
 .----------------.
 |     A data     |
 |                |
 |                |
 |                |
 |                |
 |                |
 |                |
 |                |
 |----------------|
 |                |
 |                |
 |                |
 '----------------'
```

一旦文件大小超过块大小的 1/4，我们就会切换到 CTZ 跳跃列表。这意味着我们的文件永远不会使用超过 4 倍的存储开销，随着文件大小的增长，开销会逐渐减少。

![File storage cost graph][file-cost-graph]

## 目录（Directories）

现在，我们只需要目录来存储文件。如前所述，我们希望目录和元数据对之间有严格的绑定关系，但这里有一些复杂问题需要解决。

每个目录本身是一个元数据对的链表。这使得我们可以在每个目录中存储无限数量的文件，并且不需要担心无界日志的运行时间复杂性。我们可以在元数据对中存储其他目录指针，从而形成一个目录树，类似于其他文件系统中的结构。

```
            .--------.
           .| root   |
           ||        |
           ||        |
           |'--------'
           '---|--|-'
            .-'    '-------------------------.
           v                                  v
      .--------.        .--------.        .--------.
     .| dir A  |------->| dir A  |       .| dir B  |
     ||        |       ||        |       ||        |
     ||        |       ||        |       ||        |
     |'--------'       |'--------'       |'--------'
     '---|--|-'        '----|---'        '---|--|-'
      .-'    '-.            |             .-'    '-.
     v          v           v            v          v
.--------.  .--------.  .--------.  .--------.  .--------.
| file C |  | file D |  | file E |  | file F |  | file G |
|        |  |        |  |        |  |        |  |        |
|        |  |        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'
```

主要的复杂问题再次是恒定内存下的遍历。目录树是一棵树，不幸的事实是你无法用恒定内存遍历一棵树。

幸运的是，我们的树元素是元数据对，因此与 CTZ 跳跃列表不同，我们不受严格的 COW 操作限制。我们可以做的一件事是通过树中的链表显式地启用对整个文件系统的廉价遍历。

```
            .--------.
           .| root   |-.
           ||        | |
   .-------||        |-'
   |       |'--------'
   |       '---|--|-'
   |        .-'    '-------------------------.
   |       v                                  v
   |  .--------.        .--------.        .--------.
   '->| dir A  |------->| dir A  |------->| dir B  |
     ||        |       ||        |       ||        |
     ||        |       ||        |       ||        |
     |'--------'       |'--------'       |'--------'
     '---|--|-'        '----|---'        '---|--|-'
      .-'    '-.            |             .-'    '-.
     v          v           v            v          v
.--------.  .--------.  .--------.  .--------.  .--------.
| file C |  | file D |  | file E |  | file F |  | file G |
|        |  |        |  |        |  |        |  |        |
|        |  |        |  |        |  |        |  |        |
'--------'  '--------'  '--------'  '--------'  '--------'
```

不幸的是，不坚持纯 COW 操作会带来一些问题。现在，每当我们想要操作目录树时，都需要更新多个指针。如果你熟悉设计原子数据结构，这应该会引发一些警告。

为了解决这个问题，我们的链表有一定的灵活性。它不仅包含文件系统中找到的元数据对，还允许包含由于掉电而没有父节点的元数据对。这些被称为**孤儿元数据对**。

有了孤儿的可能性，我们可以构建掉电安全的操作，这些操作维护了一个带有链表遍历的文件系统树。

向树中添加目录：

```
         .--------.
        .| root   |-.
        ||        | |
.-------||        |-'
|       |'--------'
|       '---|--|-'
|        .-'    '-.
|       v          v
|  .--------.  .--------.
'->| dir A  |->| dir C  |
  ||        | ||        |
  ||        | ||        |
  |'--------' |'--------'
  '--------'  '--------'

allocate dir B
=>
         .--------.
        .| root   |-.
        ||        | |
.-------||        |-'
|       |'--------'
|       '---|--|-'
|        .-'    '-.
|       v          v
|  .--------.    .--------.
'->| dir A  |--->| dir C  |
  ||        | .->|        |
  ||        | | ||        |
  |'--------' | |'--------'
  '--------'  | '--------'
              |
   .--------. |
  .| dir B  |-'
  ||        |
  ||        |
  |'--------'
  '--------'

insert dir B into threaded linked-list, creating an orphan
=>
         .--------.
        .| root   |-.
        ||        | |
.-------||        |-'
|       |'--------'
|       '---|--|-'
|        .-'    '-------------.
|       v                      v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | || orphan!| ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '--------'

add dir B to parent directory
=>
               .--------.
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | ||        | ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '--------'
```

删除一个目录:

```
               .--------.
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | ||        | ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '--------'

remove dir B from parent directory, creating an orphan
=>
         .--------.
        .| root   |-.
        ||        | |
.-------||        |-'
|       |'--------'
|       '---|--|-'
|        .-'    '-------------.
|       v                      v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | || orphan!| ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '--------'

remove dir B from threaded linked-list, returning dir B to free blocks
=>
         .--------.
        .| root   |-.
        ||        | |
.-------||        |-'
|       |'--------'
|       '---|--|-'
|        .-'    '-.
|       v          v
|  .--------.  .--------.
'->| dir A  |->| dir C  |
  ||        | ||        |
  ||        | ||        |
  |'--------' |'--------'
  '--------'  '--------'
```

除了正常的目录树操作外，我们还可以使用孤儿来驱逐元数据对中的块，当块损坏或超过其分配的擦除次数时。如果我们在驱逐元数据块时掉电，可能会出现文件系统引用替换块，而链表仍然包含被驱逐块的情况。我们称这种情况为**半孤儿**。

```
               .--------.
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | ||        | ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '--------'

try to write to dir B
=>
                  .--------.
                 .| root   |-.
                 ||        | |
.----------------||        |-'
|                |'--------'
|                '-|-||-|-'
|        .--------'  ||  '-----.
|       v            |v         v
|  .--------.     .--------.  .--------.
'->| dir A  |---->| dir B  |->| dir C  |
  ||        |-.   |        | ||        |
  ||        | |   |        | ||        |
  |'--------' |   '--------' |'--------'
  '--------'  |      v       '--------'
              |  .--------.
              '->| dir B  |
                 | bad    |
                 | block! |
                 '--------'

oh no! bad block detected, allocate replacement
=>
                  .--------.
                 .| root   |-.
                 ||        | |
.----------------||        |-'
|                |'--------'
|                '-|-||-|-'
|        .--------'  ||  '-------.
|       v            |v           v
|  .--------.     .--------.    .--------.
'->| dir A  |---->| dir B  |--->| dir C  |
  ||        |-.   |        | .->|        |
  ||        | |   |        | | ||        |
  |'--------' |   '--------' | |'--------'
  '--------'  |      v       | '--------'
              |  .--------.  |
              '->| dir B  |  |
                 | bad    |  |
                 | block! |  |
                 '--------'  |
                             |
                 .--------.  |
                 | dir B  |--'
                 |        |
                 |        |
                 '--------'

insert replacement in threaded linked-list, creating a half-orphan
=>
                  .--------.
                 .| root   |-.
                 ||        | |
.----------------||        |-'
|                |'--------'
|                '-|-||-|-'
|        .--------'  ||  '-------.
|       v            |v           v
|  .--------.     .--------.    .--------.
'->| dir A  |---->| dir B  |--->| dir C  |
  ||        |-.   |        | .->|        |
  ||        | |   |        | | ||        |
  |'--------' |   '--------' | |'--------'
  '--------'  |      v       | '--------'
              |  .--------.  |
              |  | dir B  |  |
              |  | bad    |  |
              |  | block! |  |
              |  '--------'  |
              |              |
              |  .--------.  |
              '->| dir B  |--'
                 | half   |
                 | orphan!|
                 '--------'

fix reference in parent directory
=>
               .--------.
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | ||        | ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '--------'
```

查找孤儿和半孤儿是昂贵的，需要对每个元数据对与每个目录条目进行 *O(n²)* 的比较。但代价是，我们获得了一个在恒定内存下工作的掉电安全文件系统。幸运的是，我们只需要在启动后的第一次分配时检查孤儿，而只读的 littlefs 可以完全忽略链表。

如果我们有某种全局状态，我们还可以存储一个标志，并避免搜索孤儿，除非我们知道在操作目录树时被中断（预示！）。

## 移动问题

我们还有最后一个挑战：移动问题。问题的表述很简单：

如何在两个目录之间原子性地移动一个文件？

在littlefs中，我们可以原子性地提交到目录，但我们无法创建一个跨越多个目录的原子提交。文件系统必须经过至少两个不同的状态才能完成移动。

更糟糕的是，文件移动是文件系统同步的一种常见形式。作为一个为断电设计的小型文件系统，我们必须正确地实现原子移动。

那么我们该怎么办？

- 我们绝对不能允许断电导致文件重复或丢失。这很容易破坏用户的代码，并且只会在极端情况下显现出来。我们之所以能够对线程链表偷懒，是因为它不面向用户，并且我们可以在内部处理这些极端情况。
- 一些文件系统将写时复制（COW）操作向上传播到树中，直到找到共同的父节点。不幸的是，这与我们的线程树交互不佳，并且会重新带来磨损向上传播的问题。
- 在littlefs的早期版本中，我们尝试通过在源目录和目标目录之间来回切换，标记和取消标记文件为移动状态，以从用户的角度实现原子移动。这种方法有效，但效果不佳。查找失败的移动操作代价高昂，并且需要为每个文件提供唯一标识符。

最终，解决移动问题需要创建一种新的机制，以便在多个元数据对之间共享信息。在littlefs中，这导致引入了一种称为“全局状态”的机制。

---

全局状态是一个小的状态集合，可以从**任何**元数据对中更新。将全局状态与元数据对在一次提交中更新多个条目的能力结合起来，为我们提供了一个强大的工具，用于构建复杂的原子操作。

全局状态是如何工作的？

全局状态作为一组增量（delta）分布在文件系统中的元数据对中。实际的全局状态可以通过将这些增量进行异或（xor）操作来构建。

```
 .--------.  .--------.  .--------.  .--------.  .--------.
.|        |->| gdelta |->|        |->| gdelta |->| gdelta |
||        | || 0x23   | ||        | || 0xff   | || 0xce   |
||        | ||        | ||        | ||        | ||        |
|'--------' |'--------' |'--------' |'--------' |'--------'
'--------'  '----|---'  '--------'  '----|---'  '----|---'
                 v                       v           v
       0x00 --> xor ------------------> xor ------> xor --> gstate 0x12
```

要从一个元数据对中更新全局状态，我们获取已知的全局状态，并将其与我们的更改以及元数据对中的任何现有增量进行异或操作。将这个新增量提交到元数据对中，就相当于将更改提交到文件系统的全局状态。

```
 .--------.  .--------.  .--------.  .--------.  .--------.
.|        |->| gdelta |->|        |->| gdelta |->| gdelta |
||        | || 0x23   | ||        | || 0xff   | || 0xce   |
||        | ||        | ||        | ||        | ||        |
|'--------' |'--------' |'--------' |'--------' |'--------'
'--------'  '----|---'  '--------'  '--|---|-'  '----|---'
                 v                     v   |         v
       0x00 --> xor ----------------> xor -|------> xor --> gstate = 0x12
                                           |                          |
                                           |                          |
change gstate to 0xab --> xor <------------|--------------------------'
=>                         |               v
                           '------------> xor
                                           |
                                           v
 .--------.  .--------.  .--------.  .--------.  .--------.
.|        |->| gdelta |->|        |->| gdelta |->| gdelta |
||        | || 0x23   | ||        | || 0x46   | || 0xce   |
||        | ||        | ||        | ||        | ||        |
|'--------' |'--------' |'--------' |'--------' |'--------'
'--------'  '----|---'  '--------'  '----|---'  '----|---'
                 v                       v           v
       0x00 --> xor ------------------> xor ------> xor --> gstate = 0xab
```

为了提高效率，我们始终在RAM中保留一份全局状态的副本。只有在挂载文件系统时，我们才需要遍历元数据对并构建全局状态。

你可能已经注意到，全局状态的代价非常高。我们在RAM中保留一个副本，并在无限数量的元数据对中保留增量。即使我们将全局状态重置为其初始值，我们也无法轻松清理磁盘上的增量。因此，保持全局状态的大小有限且非常小是非常重要的。但是，即使有严格的限制，全局状态仍然是非常宝贵的。

---

现在我们可以解决移动问题了。我们可以在创建新文件时，原子性地创建描述移动操作的全局状态，并且在删除旧文件时，原子性地清除这个移动状态。

```
               .--------.    gstate = no move
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | ||        | ||        |
  ||        | ||        | ||        |
  |'--------' |'--------' |'--------'
  '----|---'  '--------'  '--------'
       v
   .--------.
   | file D |
   |        |
   |        |
   '--------'

begin move, add reference in dir C, change gstate to have move
=>
               .--------.    gstate = moving file D in dir A (m1)
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  ||        | ||        | || gdelta |
  ||        | ||        | || =m1    |
  |'--------' |'--------' |'--------'
  '----|---'  '--------'  '----|---'
       |     .----------------'
       v    v
     .--------.
     | file D |
     |        |
     |        |
     '--------'

complete move, remove reference in dir A, change gstate to no move
=>
               .--------.    gstate = no move (m1^~m1)
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  || gdelta | ||        | || gdelta |
  || =~m1   | ||        | || =m1    |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '----|---'
                               v
                           .--------.
                           | file D |
                           |        |
                           |        |
                           '--------'
```


如果在挂载时构建全局状态的过程中，我们发现描述了一个正在进行的移动操作的信息，那么我们就知道在移动过程中发生了断电，导致文件在源目录和目标目录中都存在。如果发生这种情况，我们可以利用全局状态中的信息来解决这个移动问题，删除其中一个文件。

```
                 .--------.    gstate = moving file D in dir A (m1)
                .| root   |-.             ^
                ||        |------------> xor
.---------------||        |-'             ^
|               |'--------'               |
|               '--|-|-|-'                |
|        .--------'  |  '---------.       |
|       |            |             |      |
|       |     .----------> xor --------> xor
|       v     |      v      ^      v      ^
|  .--------. |  .--------. |  .--------. |
'->| dir A  |-|->| dir B  |-|->| dir C  | |
  ||        |-' ||        |-' || gdelta |-'
  ||        |   ||        |   || =m1    |
  |'--------'   |'--------'   |'--------'
  '----|---'    '--------'    '----|---'
       |     .---------------------'
       v    v
     .--------.
     | file D |
     |        |
     |        |
     '--------'
```

我们也可以用与移动文件相同的方式来移动目录。虽然需要考虑线程链表（threaded linked-list），但保持线程链表不变也是可行的，因为顺序并不真正影响功能。

```
               .--------.    gstate = no move (m1^~m1)
              .| root   |-.
              ||        | |
.-------------||        |-'
|             |'--------'
|             '--|-|-|-'
|        .------'  |  '-------.
|       v          v           v
|  .--------.  .--------.  .--------.
'->| dir A  |->| dir B  |->| dir C  |
  || gdelta | ||        | || gdelta |
  || =~m1   | ||        | || =m1    |
  |'--------' |'--------' |'--------'
  '--------'  '--------'  '----|---'
                               v
                           .--------.
                           | file D |
                           |        |
                           |        |
                           '--------'

begin move, add reference in dir C, change gstate to have move
=>
                .--------.    gstate = moving dir B in root (m1^~m1^m2)
               .| root   |-.
               ||        | |
.--------------||        |-'
|              |'--------'
|              '--|-|-|-'
|        .-------'  |  '----------.
|       v           |              v
|  .--------.       |          .--------.
'->| dir A  |-.     |       .->| dir C  |
  || gdelta | |     |       | || gdelta |
  || =~m1   | |     |       | || =m1^m2 |
  |'--------' |     |       | |'--------'
  '--------'  |     |       | '---|--|-'
              |     |    .-------'   |
              |     v   v   |        v
              |  .--------. |    .--------.
              '->| dir B  |-'    | file D |
                ||        |      |        |
                ||        |      |        |
                |'--------'      '--------'
                '--------'

complete move, remove reference in root, change gstate to no move
=>
             .--------.    gstate = no move (m1^~m1^m2^~m2)
            .| root   |-.
            || gdelta | |
.-----------|| =~m2   |-'
|           |'--------'
|           '---|--|-'
|        .-----'    '-----.
|       v                  v
|  .--------.          .--------.
'->| dir A  |-.     .->| dir C  |
  || gdelta | |     | || gdelta |
  || =~m1   | |     '-|| =m1^m2 |-------.
  |'--------' |       |'--------'       |
  '--------'  |       '---|--|-'        |
              |        .-'    '-.       |
              |       v          v      |
              |  .--------.  .--------. |
              '->| dir B  |--| file D |-'
                ||        |  |        |
                ||        |  |        |
                |'--------'  '--------'
                '--------'
```

全局状态为我们提供了一个强大的工具，可以用来解决移动问题。结果出乎意料地高效，仅需要最少数量的状态，并且使用的提交次数与简单的移动操作相同。此外，全局状态还为我们提供了一些持久化的状态，可以用于其他一些小的改进。

## 总结

这就是littlefs，感谢阅读！


[wikipedia-flash]: https://en.wikipedia.org/wiki/Flash_memory
[wikipedia-sna]: https://en.wikipedia.org/wiki/Serial_number_arithmetic
[wikipedia-crc]: https://en.wikipedia.org/wiki/Cyclic_redundancy_check
[wikipedia-cow]: https://en.wikipedia.org/wiki/Copy-on-write
[wikipedia-B-tree]: https://en.wikipedia.org/wiki/B-tree
[wikipedia-B+-tree]: https://en.wikipedia.org/wiki/B%2B_tree
[wikipedia-skip-list]: https://en.wikipedia.org/wiki/Skip_list
[wikipedia-ctz]: https://en.wikipedia.org/wiki/Count_trailing_zeros
[wikipedia-ecc]: https://en.wikipedia.org/wiki/Error_correction_code
[wikipedia-hamming-bound]: https://en.wikipedia.org/wiki/Hamming_bound
[wikipedia-dynamic-wear-leveling]: https://en.wikipedia.org/wiki/Wear_leveling#Dynamic_wear_leveling
[wikipedia-static-wear-leveling]: https://en.wikipedia.org/wiki/Wear_leveling#Static_wear_leveling
[wikipedia-ftl]: https://en.wikipedia.org/wiki/Flash_translation_layer

[oeis]: https://oeis.org
[A001511]: https://oeis.org/A001511
[A005187]: https://oeis.org/A005187

[fat]: https://en.wikipedia.org/wiki/Design_of_the_FAT_file_system
[ext2]: http://e2fsprogs.sourceforge.net/ext2intro.html
[jffs]: https://www.sourceware.org/jffs2/jffs2-html
[yaffs]: https://yaffs.net/documents/how-yaffs-works
[spiffs]: https://github.com/pellepl/spiffs/blob/master/docs/TECH_SPEC
[ext4]: https://ext4.wiki.kernel.org/index.php/Ext4_Design
[ntfs]: https://en.wikipedia.org/wiki/NTFS
[btrfs]: https://btrfs.wiki.kernel.org/index.php/Btrfs_design
[zfs]: https://en.wikipedia.org/wiki/ZFS

[cow]: https://upload.wikimedia.org/wikipedia/commons/0/0c/Cow_female_black_white.jpg
[elephant]: https://upload.wikimedia.org/wikipedia/commons/3/37/African_Bush_Elephant.jpg
[ram]: https://upload.wikimedia.org/wikipedia/commons/9/97/New_Mexico_Bighorn_Sheep.JPG
[metadata-formula1]: https://latex.codecogs.com/svg.latex?cost%20%3D%20n%20&plus;%20n%20%5Cfrac%7Bs%7D%7Bd&plus;1%7D
[metadata-formula2]: https://latex.codecogs.com/svg.latex?s%20%3D%20r%20%5Cfrac%7Bsize%7D%7Bn%7D
[metadata-formula3]: https://latex.codecogs.com/svg.latex?d%20%3D%20%281-r%29%20%5Cfrac%7Bsize%7D%7Bn%7D
[metadata-formula4]: https://latex.codecogs.com/svg.latex?cost%20%3D%20n%20&plus;%20n%20%5Cfrac%7Br%5Cfrac%7Bsize%7D%7Bn%7D%7D%7B%281-r%29%5Cfrac%7Bsize%7D%7Bn%7D&plus;1%7D

[ctz-formula1]: https://latex.codecogs.com/svg.latex?%5Clim_%7Bn%5Cto%5Cinfty%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Cleft%28%5Ctext%7Bctz%7D%28i%29&plus;1%5Cright%29%20%3D%20%5Csum_%7Bi%3D0%7D%5Cfrac%7B1%7D%7B2%5Ei%7D%20%3D%202
[ctz-formula2]: https://latex.codecogs.com/svg.latex?B%20%3D%20%5Cfrac%7Bw%7D%7B8%7D%5Cleft%5Clceil%5Clog_2%5Cleft%28%5Cfrac%7B2%5Ew%7D%7BB-2%5Cfrac%7Bw%7D%7B8%7D%7D%5Cright%29%5Cright%5Crceil
[ctz-formula3]: https://latex.codecogs.com/svg.latex?N%20%3D%20%5Csum_i%5En%5Cleft%5BB-%5Cfrac%7Bw%7D%7B8%7D%5Cleft%28%5Ctext%7Bctz%7D%28i%29&plus;1%5Cright%29%5Cright%5D
[ctz-formula4]: https://latex.codecogs.com/svg.latex?%5Csum_i%5En%5Cleft%28%5Ctext%7Bctz%7D%28i%29&plus;1%5Cright%29%20%3D%202n-%5Ctext%7Bpopcount%7D%28n%29
[ctz-formula5]: https://latex.codecogs.com/svg.latex?N%20%3D%20Bn%20-%20%5Cfrac%7Bw%7D%7B8%7D%5Cleft%282n-%5Ctext%7Bpopcount%7D%28n%29%5Cright%29
[ctz-formula6]: https://latex.codecogs.com/svg.latex?n%20%3D%20%5Cleft%5Clfloor%5Cfrac%7BN-%5Cfrac%7Bw%7D%7B8%7D%5Cleft%28%5Ctext%7Bpopcount%7D%5Cleft%28%5Cfrac%7BN%7D%7BB-2%5Cfrac%7Bw%7D%7B8%7D%7D-1%5Cright%29&plus;2%5Cright%29%7D%7BB-2%5Cfrac%7Bw%7D%7B8%7D%7D%5Cright%5Crfloor
[ctz-formula7]: https://latex.codecogs.com/svg.latex?%5Cmathit%7Boff%7D%20%3D%20N%20-%20%5Cleft%28B-2%5Cfrac%7Bw%7D%7B8%7D%5Cright%29n%20-%20%5Cfrac%7Bw%7D%7B8%7D%5Ctext%7Bpopcount%7D%28n%29
[metadata-cost-graph]: https://raw.githubusercontent.com/geky/littlefs/gh-images/metadata-cost.svg?sanitize=true
[wear-distribution-graph]: https://raw.githubusercontent.com/geky/littlefs/gh-images/wear-distribution.svg?sanitize=true
[file-cost-graph]: https://raw.githubusercontent.com/geky/littlefs/gh-images/file-cost.svg?sanitize=true
